{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"README-AI","text":"README-AI Your AI-Powered README Generator Designed for simplicity, customization, and developer productivity. <p>README-AI is a developer tool and framework that combines robust data processing modules with generative AI models. It streamlines documentation and enhances developer productivity by auto-generating comprehensive <code>README.md</code> files.</p> <p>With README-AI, you can:</p> <ul> <li>Automate Documentation: Synchronize data from third-party sources and generate documentation automatically.</li> <li>Customize &amp; Flexibly Style: Choose from dozens of options for styling, formatting, badges, header designs, and more.</li> <li>Support Multiple Languages &amp; Projects: Work across a wide range of programming languages and project types.</li> <li>Leverage Multiple LLMs: Compatible with <code>OpenAI</code>, <code>Ollama</code>, <code>Anthropic</code>, <code>Google Gemini</code> and <code>Offline Mode</code>.</li> <li>Follow Markdown Best Practices: Create clean, professional-looking documentation using Markdown formatting best practices.</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li> Automated README generation</li> <li> Customizable output and styling</li> <li> Language and project agnostic</li> <li> Multi-LLM support</li> <li> Markdown best practices</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>If you're ready to jump right in, here's how to get started:</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install readmeai\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<pre><code>readmeai -r &lt;repository_url&gt; -o &lt;output_file&gt;\n</code></pre> <p>Otherwise you can explore the documentation for more detailed information. Cheers!</p>"},{"location":"contributing/","title":"Contributing Guidelines","text":"<p>Thanks for your interest in contributing to readme-ai. Please review these guidelines to ensure a smooth process.</p>"},{"location":"contributing/#make-valuable-contributions","title":"Make Valuable Contributions","text":"<p>Strive to make useful, creative, and high quality contributions. This isn't meant to be a high bar, but more of a guiding principle and philosophy. Here's what we mean by these terms:</p> <p>Useful: Solve common problems, use cases, bugs, or new features.</p> <p>Creative: Innovative and helping us all grow and learn new things.</p> <p>High Quality: Well-written, structured, and explained.</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to Contribute","text":"<p>To improve and grow the project, we need your help! Here are some ways to get involved:</p> Activity Ideas \ud83d\udc4b Discussions Start a discussion by asking a question or making a suggestion. \ud83d\udc1b Open an Issue Find unhandled exceptions and bugs in the codebase. \ud83d\udcc4 Documentation Write documentation for the project. \ud83e\uddea Testing Write unit tests to increase code coverage. \ud83e\udde9 Feature Requests Brainstorm new ideas such as a CLI option to select any language. \ud83d\udee0\ufe0f Code Contributions Contribute to the codebase and submit a pull request. \ud83d\udd22 Code Readability Find ways to make code more readable and easier to understand. \ud83e\udd14 Other Anything else you can think of! <p>These are just a few examples, and we welcome any other ideas you may have!</p>"},{"location":"contributing/#submitting-changes","title":"Submitting Changes","text":"<ol> <li>Fork the repository and clone it locally.</li> <li>Create a new branch with a descriptive name i.e <code>feature/new-feature-name</code> or <code>bugfix-issue-123</code>.</li> <li>Make focused changes with clear commits.</li> <li>Open a pull request document the changes you've made and why they're necessary.</li> <li>Respond to code reviews from maintainers.</li> </ol>"},{"location":"contributing/#code-quality-expectations","title":"Code Quality Expectations","text":"<ul> <li>Clear, well-documented code</li> <li>Include tests for new code</li> <li>Follow project style standards</li> <li>Rebase onto latest main branch</li> </ul>"},{"location":"contributing/#attribution","title":"Attribution","text":"<p>Contributors to our project will be acknowledged in the project's README.md file.</p>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing to our project, you agree to license your contributions under the project's open source license. The project's license can be found in the LICENSE</p> <p>Thank you for your interest in contributing to readme-ai! We appreciate your help and look forward to working with you.</p>"},{"location":"faq/","title":"README-AI Frequently Asked Questions","text":""},{"location":"faq/#general-questions","title":"General Questions","text":""},{"location":"faq/#q-what-is-readme-ai","title":"Q: What is README-AI?","text":"<p>A: README-AI is a tool that automatically generates comprehensive README files for your projects using artificial intelligence.</p>"},{"location":"faq/#q-which-ai-models-does-readme-ai-support","title":"Q: Which AI models does README-AI support?","text":"<p>A: README-AI primarily uses OpenAI's GPT models, but there are ongoing efforts to add support for other models like Claude, Azure OpenAI, Cohere, and Llama2 (via Replicate).</p>"},{"location":"faq/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"faq/#q-how-do-i-install-readme-ai","title":"Q: How do I install README-AI?","text":"<p>A: You can install README-AI using pip: <pre><code>pip install readmeai\n</code></pre> Alternatively, you can use Docker: <pre><code>docker run -it -e OPENAI_API_KEY=your_key_here -v \"$(pwd)\":/app zeroxeli/readme-ai:latest\n</code></pre></p>"},{"location":"faq/#q-im-getting-an-error-when-trying-to-install-on-ubuntu-how-can-i-fix-it","title":"Q: I'm getting an error when trying to install on Ubuntu. How can I fix it?","text":"<p>A: If you're encountering issues with conda environment creation, try using a virtual environment with pip instead. Ensure you have Python 3.8 or higher installed.</p>"},{"location":"faq/#usage","title":"Usage","text":""},{"location":"faq/#q-how-do-i-generate-a-readme-for-my-project","title":"Q: How do I generate a README for my project?","text":"<p>A: Use the following command: <pre><code>readmeai -o readme-ai.md -r https://github.com/your-username/your-repo\n</code></pre> Replace the URL with your repository link.</p>"},{"location":"faq/#q-can-i-use-readme-ai-with-private-repositories","title":"Q: Can I use README-AI with private repositories?","text":"<p>A: Yes, but you may need to provide authentication. For Bitbucket, use the format: <pre><code>https://username:bitbucket_apikey@bitbucket.org/username/repo\n</code></pre></p>"},{"location":"faq/#q-does-readme-ai-work-with-gitlab-repositories","title":"Q: Does README-AI work with GitLab repositories?","text":"<p>A: Yes, README-AI supports GitLab repositories. Use the same command format as with GitHub repos.</p>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#q-im-getting-a-404-not-found-error-what-should-i-do","title":"Q: I'm getting a \"404 Not Found\" error. What should I do?","text":"<p>A: Ensure your OpenAI API key is correct and has sufficient permissions. Also, check if you're using the correct API endpoint.</p>"},{"location":"faq/#q-the-script-runs-but-doesnt-generate-a-file-why","title":"Q: The script runs but doesn't generate a file. Why?","text":"<p>A: Check the permissions in your current directory. Ensure README-AI has write access to create the output file.</p>"},{"location":"faq/#q-im-seeing-a-429-too-many-requests-error-how-can-i-resolve-this","title":"Q: I'm seeing a \"429 Too Many Requests\" error. How can I resolve this?","text":"<p>A: This error occurs when you've exceeded the rate limit for the OpenAI API. Wait a while before trying again, or consider upgrading your API plan.</p>"},{"location":"faq/#q-why-am-i-getting-a-notfound-object-is-not-iterable-error","title":"Q: Why am I getting a \"NotFound object is not iterable\" error?","text":"<p>A: This error may occur if you're using an incompatible model. Ensure you're using a supported model like \"gpt-3.5-turbo\" or \"gpt-4\".</p>"},{"location":"faq/#features-and-customization","title":"Features and Customization","text":""},{"location":"faq/#q-can-i-use-readme-ai-with-languages-other-than-english","title":"Q: Can I use README-AI with languages other than English?","text":"<p>A: While README-AI primarily generates content in English, there are ongoing efforts to add internationalization (i18n) support for languages like Spanish and Italian.</p>"},{"location":"faq/#q-is-it-possible-to-use-readme-ai-in-azure-devops","title":"Q: Is it possible to use README-AI in Azure DevOps?","text":"<p>A: While there isn't native integration, you could potentially use README-AI as part of your Azure DevOps pipeline by incorporating it into your build or release process.</p>"},{"location":"faq/#q-can-i-customize-the-openai-endpoint-or-model-used","title":"Q: Can I customize the OpenAI endpoint or model used?","text":"<p>A: There are ongoing efforts to make the configuration more extensible, including options to specify different endpoints (like Azure OpenAI) and models.</p>"},{"location":"faq/#contributing","title":"Contributing","text":""},{"location":"faq/#q-how-can-i-contribute-to-readme-ai","title":"Q: How can I contribute to README-AI?","text":"<p>A: You can contribute by submitting pull requests on GitHub. Areas of contribution include adding support for new AI models, improving documentation, adding tests, and fixing bugs.</p> <p>If you have any other questions or issues, please check the GitHub repository or open a new issue for support.</p>"},{"location":"philosophy/","title":"Philosophy and Vision","text":""},{"location":"philosophy/#empowering-developers-enlightening-projects","title":"Empowering Developers, Enlightening Projects","text":"<p>Readme-ai envisions a future where every software project, regardless of size or complexity, is accompanied by clear, comprehensive, and up-to-date documentation. We strive to create an ecosystem where documentation is no longer an afterthought but an integral, effortless part of the development process.</p>"},{"location":"philosophy/#our-core-vision","title":"Our Core Vision","text":"<ol> <li>Democratize Quality Documentation</li> <li>Make professional-grade documentation accessible to all developers, from hobbyists to enterprise teams.</li> <li> <p>Break down language barriers by offering multilingual documentation generation.</p> </li> <li> <p>Accelerate Open Source Adoption</p> </li> <li>Enhance the discoverability and usability of open source projects through superior documentation.</li> <li> <p>Foster a more inclusive open source community by lowering the barrier to contribution.</p> </li> <li> <p>Evolve with AI Advancements</p> </li> <li>Continuously integrate cutting-edge AI technologies to improve documentation quality and generation speed.</li> <li> <p>Pioneer new ways of understanding and describing code structures and functionalities.</p> </li> <li> <p>Cultivate Documentation Best Practices</p> </li> <li>Establish Readme-ai as the gold standard for project documentation in the software industry.</li> <li> <p>Encourage a culture where well-documented projects are the norm, not the exception.</p> </li> <li> <p>Enhance Developer Productivity</p> </li> <li>Free developers to focus on coding by automating the documentation process.</li> <li> <p>Reduce the time from development to deployment by streamlining the documentation workflow.</p> </li> <li> <p>Promote Code Understanding</p> </li> <li>Facilitate better code comprehension across teams and organizations.</li> <li> <p>Bridge the gap between technical and non-technical stakeholders through clear, AI-generated explanations.</p> </li> <li> <p>Ensure Adaptability and Extensibility</p> </li> <li>Create a flexible platform that can easily integrate with various development workflows and tools.</li> <li> <p>Build a robust plugin ecosystem that allows the community to extend Readme-ai's capabilities.</p> </li> <li> <p>Champion Ethical AI Use</p> </li> <li>Lead by example in the responsible and transparent use of AI in developer tools.</li> <li>Prioritize user privacy and data security in all aspects of our AI-driven processes.</li> </ol>"},{"location":"philosophy/#long-term-impact","title":"Long-Term Impact","text":"<p>We see Readme-ai as a catalyst for a paradigm shift in software development practices. By making high-quality documentation effortless and ubiquitous, we aim to:</p> <ul> <li>Accelerate innovation by making it easier for developers to build upon each other's work.</li> <li>Improve software quality by encouraging better-documented and more maintainable codebases.</li> <li>Enhance collaboration within and between development teams through clearer project communication.</li> <li>Increase the overall efficiency of the software development lifecycle.</li> </ul> <p>Through Readme-ai, we aspire to create a world where every line of code is matched by a line of clear, concise, and helpful documentation, empowering developers and enlightening projects for the benefit of all.</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":""},{"location":"troubleshooting/#help-menus","title":"Help Menus","text":"<p>The <code>--help</code> flag can be used to view the help menu for a command, e.g., for <code>readmeai</code>:</p> <pre><code>\u276f readmeai --help\n</code></pre>"},{"location":"troubleshooting/#viewing-the-version","title":"Viewing the Version","text":"<p>When seeking help, it's important to determine the version of readmeai that you're using \u2014 sometimes the problem is already solved in a newer version.</p> <p>To check the installed version:</p> <pre><code>\u276f readmeai --version\n</code></pre> <p>The following are also valid:</p> <pre><code>\u276f readmeai -V\n\u276f readmeai pip --version\n</code></pre>"},{"location":"troubleshooting/#open-an-issue-on-github","title":"Open an issue on GitHub","text":"<p>The issue tracker on GitHub is a good place to report bugs and request features. Make sure to search for similar issues first, as it is common for someone else to encounter the same problem.</p>"},{"location":"troubleshooting/#faq","title":"FAQ","text":"<p>See the FAQ for answers to common questions and troubleshooting tips.</p>"},{"location":"why/","title":"Why use README-AI?","text":"<p>In the fast-paced world of software development, clear and comprehensive documentation is crucial. Yet, creating and maintaining high-quality README files can be time-consuming and often overlooked. This is where Readme-ai comes in, revolutionizing the way developers approach project documentation.</p>"},{"location":"why/#automated-documentation-generation","title":"Automated Documentation Generation","text":"<p>Readme-ai harnesses the power of artificial intelligence to automatically generate detailed, structured README files for your projects. By analyzing your codebase, Readme-ai creates documentation that is:</p> <ul> <li>Comprehensive: Covers all essential aspects of your project, from installation instructions to usage examples.</li> <li>Consistent: Maintains a uniform structure across all your projects, enhancing readability and professionalism.</li> </ul>"},{"location":"why/#time-saving-and-efficient","title":"Time-Saving and Efficient","text":"<ul> <li>Focus on Coding: Spend more time writing code and less time worrying about documentation.</li> <li>Quick Setup: Get started with minimal configuration, allowing you to generate a README in minutes.</li> <li>Customizable Templates: Fine-tune the output to match your project's specific needs and your personal style.</li> </ul>"},{"location":"why/#enhanced-project-visibility","title":"Enhanced Project Visibility","text":"<ul> <li>Professional Appearance: Engage potential users and contributors with polished, well-structured documentation.</li> <li>Comprehensive Overview: Provide a clear, concise summary of your project, making it easier for others to understand and use.</li> <li>SEO-Friendly: Generated READMEs are optimized for search engines, improving your project's discoverability.</li> </ul>"},{"location":"why/#integration-and-flexibility","title":"Integration and Flexibility","text":"<ul> <li>Extensible: Customize and extend readme-ai to fit your specific documentation needs.</li> <li>Multiple AI Backends: Choose from various AI providers (OpenAI, Ollama, Google Gemini) or use the offline mode for sensitive projects.</li> <li>Language Agnostic: Works with a wide range of programming languages and project types, ensuring compatibility with your existing codebase.</li> </ul>"},{"location":"why/#community-driven-development","title":"Community-Driven Development","text":"<ul> <li> <p>Open Source: Benefit from and contribute to a growing ecosystem of documentation tools and best practices.</p> </li> <li> <p>Continuous Improvement: Regular updates and improvements driven by community feedback and contributions.</p> </li> <li> <p>Shared Knowledge: Learn from and contribute to a gallery of exemplary READMEs generated by the community.</p> </li> </ul>"},{"location":"why/#key-features","title":"Key Features","text":"<ol> <li> <p>Flexible README Generation: Combines robust repository context extraction with generative AI to create detailed and accurate README files.</p> </li> <li> <p>Customizable Output: Offers numerous CLI options for tailoring the README to your project's needs:</p> <ul> <li> <p>Badge styles and colors</p> </li> <li> <p>Header designs</p> </li> <li> <p>Table of contents styles</p> </li> <li> <p>Project logos</p> </li> </ul> </li> <li> <p>Language Agnostic: Works with a wide range of programming languages and project types, automatically detecting and summarizing key aspects of your codebase.</p> </li> <li> <p>Project Analysis: Automatically extracts and presents important information about your project:</p> <ul> <li>Directory structure</li> <li>File summaries</li> <li>Dependencies</li> <li>Setup instructions</li> </ul> </li> <li> <p>Multi-LLM Support: Compatible with various language model APIs, including:</p> <ul> <li>OpenAI</li> <li>Ollama</li> <li>Anthropic</li> <li>Google Gemini</li> <li>Offline Mode</li> </ul> </li> <li> <p>Offline Mode: Generate a basic README structure without requiring an internet connection or API calls.</p> </li> <li> <p>Markdown Expertise: Leverages best practices in Markdown formatting for clean, professional-looking documentation.</p> </li> </ol>"},{"location":"blog/","title":"Blog","text":"<p>\u2728 coming soon ...</p>"},{"location":"configuration/badges/","title":"Badges","text":"<p>A badge is a simple embeddable icon that displays various metrics such as the number of stars or forks for a repository, languages used in the project, CI/CD build status, test coverage, the license of the project, and more. Badges are a great way to provide quick information about your project to users and visitors.</p> <p>README-AI offers various badge styles to enhance your project's README. This guide explains how to use and customize these badges.</p>"},{"location":"configuration/badges/#badge-styles","title":"Badge Styles","text":"<p>Use the <code>--badge-style</code> option to select from the following styles:</p> defaultflatflat-squarefor-the-badgeplasticskillsskills-lightsocial <p> </p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"configuration/badges/#how-it-works","title":"How It Works","text":"<p>README-AI automatically detects your project's dependencies and technologies during the repository ingestion process. It then uses these dependencies and technologies to generate a comprehensive list of relevant badges for your project.</p> <p>When you provide the <code>--badge-style</code> option to the <code>readmeai</code> command, two sets of badges are generated:</p> <ol> <li>Default Metadata Badges: The default set is always included in the generated README file. The default badges include the project <code>license</code>, <code>last commit</code>, <code>top language</code>, and <code>total languages</code>.</li> <li>Project Dependency Badges: When the <code>--badge-style</code> argument is provided to the CLI, a second badge set is generated, representing the extracted dependencies and metadata from your codebase.</li> </ol> <p>The badge sets are formatted in the README header and provide the reader with a quick overview of the project's key metrics and technologies.</p>"},{"location":"configuration/badges/#example-usage","title":"Example Usage","text":"<p>Let's generate a README with custom badge colors and styles using the <code>--badge-color</code> and <code>--badge-style</code> options:</p> <pre><code>readmeai --badge-color orange \\\n         --badge-style flat-square \\\n         --repository https://github.com/eli64s/readme-ai\n</code></pre> <p>The command above generates a README with the following badge configuration:</p> <p>Example</p> Badge Generation <p> </p> <p>Built with the tools and technologies:</p> <p> </p> <p>The <code>--badge-color</code> option only modifies the default badge set, while the <code>--badge-style</code> option is applied to both the default and project dependency badges</p>"},{"location":"configuration/badges/#tips-for-using-badges","title":"Tips for Using Badges","text":"<ul> <li>Choose a badge style that complements your project's overall design.</li> <li>Use badges to highlight relevant information about your project, such as license, build status, and test coverage.</li> <li>Don't overuse badges \u2013 too many can clutter your README and make it hard to read.</li> <li>Ensure that all badge links are correct and up-to-date.</li> <li>Consider using custom badges for project-specific information or metrics.</li> </ul>"},{"location":"configuration/badges/#references","title":"References","text":"<p>Thank you to the following projects for providing the badges used in this project:</p> <ul> <li>Shields.io</li> <li>Aveek-Saha/GitHub-Profile-Badges</li> <li>Ileriayo/Markdown-Badges</li> <li>tandpfun/skill-icons ```</li> </ul>"},{"location":"configuration/cli_reference/","title":"Configuration","text":"<p>README-AI offers a wide range of configuration options to customize your README generation. This page provides a comprehensive list of all available options with detailed explanations.</p>"},{"location":"configuration/cli_reference/#cli-options","title":"CLI Options","text":"Option Description Default Impact <code>--align</code> Text alignment in header <code>center</code> Affects the visual layout of the README header <code>--api</code> LLM API service <code>offline</code> Determines which AI service is used for content generation <code>--badge-color</code> Badge color (name or hex) <code>0080ff</code> Customizes the color of status badges in the README <code>--badge-style</code> Badge icon style type <code>flat</code> Changes the visual style of status badges <code>--base-url</code> Base URL for the repository <code>v1/chat/completions</code> Used for API requests to the chosen LLM service <code>--context-window</code> Max context window of LLM API <code>3999</code> Limits the amount of context provided to the LLM <code>--emojis</code> Add emojis to README sections <code>False</code> Adds visual flair to section headers <code>--header-style</code> Header template style <code>classic</code> Changes the overall look of the README header <code>--image</code> Project logo image <code>blue</code> Sets the main image displayed in the README <code>--model</code> Specific LLM model to use <code>gpt-3.5-turbo</code> Chooses the AI model for content generation <code>--output</code> Output filename <code>readme-ai.md</code> Specifies the name of the generated README file <code>--rate-limit</code> Max API requests per minute <code>5</code> Prevents exceeding API rate limits <code>--repository</code> Repository URL or local path <code>None</code> Specifies the project to analyze <code>--temperature</code> Creativity level for generation <code>0.9</code> Controls the randomness of the AI's output <code>--toc-style</code> Table of contents style <code>bullet</code> Changes the format of the table of contents <code>--top-p</code> Top-p sampling probability <code>0.9</code> Fine-tunes the AI's output diversity <code>--tree-depth</code> Max depth of directory tree <code>2</code> Controls the detail level of the project structure <p>Some options have a significant impact on the generated README's appearance and content. Experiment with different settings to find the best configuration for your project.</p>"},{"location":"configuration/emojis/","title":"Emojis","text":"<p>Emojis are a fun way to add some personality to your README.md file. README-AI allows you to automatically add emojis to all headers in the generated README file by providing the <code>--emojis</code> option to the <code>readmeai</code> command.</p>"},{"location":"configuration/emojis/#how-it-works","title":"How It Works","text":"<p>When you provide the <code>--emojis</code> option to the <code>readmeai</code> command, README-AI automatically adds emojis to all headers in the generated README file.</p> Default (emojis disabled)Emojis Enabled <p></p> <p></p>"},{"location":"configuration/emojis/#readme-ai-streamlit","title":"<code>README-AI-STREAMLIT</code>","text":""},{"location":"configuration/emojis/#codebase-efficiency-elevated-documentation-enhanced","title":"Codebase Efficiency Elevated, Documentation Enhanced!","text":"<p><p> </p> <p> Built with the tools and technologies: </p> <p> </p> </p>"},{"location":"configuration/emojis/#table-of-contents","title":"Table of Contents","text":"<ul> <li> Overview</li> <li> Features</li> <li> Project Structure</li> <li> Project Index</li> <li> Getting Started</li> <li> Prerequisites</li> <li> Installation</li> <li> Usage</li> <li> Tests</li> <li> Roadmap</li> <li> Contributing</li> <li> License</li> <li> Acknowledgments</li> </ul>"},{"location":"configuration/emojis/#overview","title":"Overview","text":"<p>...</p>"},{"location":"configuration/emojis/#readme-ai-streamlit_1","title":"<code>README-AI-STREAMLIT</code>","text":""},{"location":"configuration/emojis/#codebase-efficiency-elevated-documentation-enhanced_1","title":"Codebase Efficiency Elevated, Documentation Enhanced!","text":"<p><p> </p> <p> Built with the tools and technologies: </p> <p> </p> </p>"},{"location":"configuration/emojis/#table-of-contents_1","title":"\ud83d\udcd2 Table of Contents","text":"<ul> <li>\ud83d\udccd Overview</li> <li>\ud83d\udc7e Features</li> <li>\ud83d\udcc1 Project Structure</li> <li>\ud83d\udcc2 Project Index</li> <li>\ud83d\ude80 Getting Started</li> <li>\ud83d\udccb Prerequisites</li> <li>\u2699\ufe0f Installation</li> <li>\ud83e\udd16 Usage</li> <li>\ud83e\uddea Tests</li> <li>\ud83d\udccc Roadmap</li> <li>\ud83d\udd30 Contributing</li> <li>\ud83c\udf97 License</li> <li>\ud83d\ude4c Acknowledgments</li> </ul>"},{"location":"configuration/emojis/#overview_1","title":"\ud83d\udccd Overview","text":"<p>...</p>"},{"location":"configuration/header/","title":"Header Templates","text":"<p>A header is the first section of a README file that typically contains the project's logo, name, slogan, and badges. It serves as an introduction to the project and provides context for its contents.</p> <p>README-AI allows you to customize the style of the header in your generated README files by selecting from a set of predefined header templates. This feature lets you control the layout and appearance of your project's header section, including the alignment of logos, repository names, and additional badges or icons.</p>"},{"location":"configuration/header/#cli-usage-for-header-styles","title":"CLI Usage for Header Styles","text":"<p>When using the <code>readmeai</code> CLI, you can define the header style using the <code>--header-style</code> option. This enables you to select from a variety of predefined styles.</p>"},{"location":"configuration/header/#supported-header-styles","title":"Supported Header Styles:","text":"<ol> <li>Classic (<code>classic</code>)</li> <li> <p>A traditional, centered layout with a large project logo, title, and badges. Default style if no header style is specified.</p> </li> <li> <p>Compact (<code>compact</code>)</p> </li> <li> <p>A space-efficient layout with the logo aligned to the left, followed by the project name and badges in a smaller footprint.</p> </li> <li> <p>Modern (<code>modern</code>)</p> </li> <li>A sleek and modern look with the logo aligned to the right and a minimalistic header format.</li> </ol>"},{"location":"configuration/header/#example-cli-command","title":"Example CLI Command","text":"<p>To generate a README file with the Modern header style, run the following command:</p> <pre><code>readmeai --repository ./my_project --header-style modern --output README.md\n</code></pre> <p>In this example: - The <code>--repository</code> flag points to your local project directory or a remote repository. - The <code>--header-style modern</code> flag specifies that the \"Modern\" header template should be used. - The <code>--output README.md</code> flag sets the output file name to <code>README.md</code>.</p>"},{"location":"configuration/header/#another-example-with-compact-header-style","title":"Another Example with Compact Header Style","text":"<p>To generate a README file with the Compact header style, run:</p> <pre><code>readmeai --repository ./my_project --header-style compact --output README.md\n</code></pre> <p>This will generate a more condensed version of the header, suitable for projects where you want to minimize the space taken by the header.</p>"},{"location":"configuration/header/#available-header-styles","title":"Available Header Styles","text":"<pre><code>-hs, --header-style [classic|compact|modern]\n</code></pre> <p>The <code>--header-style</code> option supports the following values:</p> <ul> <li>classic: Traditional centered header with logo and title.</li> <li>compact: Left-aligned logo and a compact project title.</li> <li>modern: Right-aligned logo with a modern aesthetic for the header.</li> </ul>"},{"location":"configuration/project_logo/","title":"Project Logo","text":"<p>A project logo is a visual representation of your project that appears at the top of your README file. It helps to brand your project and make it more recognizable. README-AI offers various options for adding a logo to your project's README.</p>"},{"location":"configuration/project_logo/#logo-options","title":"Logo Options","text":"<p>Use the <code>--image</code> option to select from the following logo styles:</p> BlueGradientBlackCloudPurpleGrey <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"configuration/project_logo/#how-it-works","title":"How It Works","text":"<p>README-AI provides several ways to include a logo in your project's README:</p> <ol> <li>Default Images: Choose from a set of pre-defined logos.</li> <li>Custom Images: Use your own image by providing a URL or file path.</li> <li>LLM-Generated Images: Generate a unique logo using AI (requires an LLM API).</li> </ol> <p>The selected or generated logo will be placed at the top of your README file, helping to visually identify your project.</p>"},{"location":"configuration/project_logo/#usage-examples","title":"Usage Examples","text":""},{"location":"configuration/project_logo/#using-a-default-image","title":"Using a Default Image","text":"<p>To use one of the default images, specify the image name with the <code>--image</code> option:</p> <pre><code>readmeai --image gradient --repository https://github.com/username/project\n</code></pre>"},{"location":"configuration/project_logo/#using-a-custom-image","title":"Using a Custom Image","text":"<p>To use a custom image, use the <code>--image custom</code> option:</p> <pre><code>readmeai --image custom --repository https://github.com/username/project\n</code></pre> <p>You will be prompted to provide an image file path or URL:</p> <pre><code>Provide an image file path or URL:\n</code></pre>"},{"location":"configuration/project_logo/#llm-generated-logo","title":"LLM Generated Logo","text":"<p>To generate a logo using an LLM API (e.g., OpenAI), use the <code>--image llm</code> option:</p> <pre><code>readmeai --image llm --api openai --repository https://github.com/username/project\n</code></pre> <p>This will generate a unique project logo using the specified LLM API.</p>"},{"location":"configuration/project_logo/#example-output","title":"Example Output","text":"<p>Here's an example of how a generated README header might look with a logo:</p> <p>Example</p> Example 1Example 2Example 3 <p><p> </p> Your Project Name <p> Your project's tagline or brief description </p> </p> <p><p> </p> Your Project Name <p> Your project's tagline or brief description </p> </p> <p><p> </p> Your Project Name <p> Your project's tagline or brief description </p> </p> <p> The quality and relevance of LLM-generated logos can vary. It's a good idea to review and potentially edit the generated logo to ensure it meets your project's needs.</p>"},{"location":"configuration/project_logo/#tips-for-using-project-logos","title":"Tips for Using Project Logos","text":"<ul> <li>Choose a logo that represents your project's purpose or theme.</li> <li>Ensure the logo is clear and recognizable even at smaller sizes.</li> <li>If using a custom image, make sure it's high quality and appropriately sized.</li> <li>When using LLM-generated logos, you may want to generate several options to choose from.</li> <li>Consider how the logo will look alongside your project's badges and other README content.</li> <li>If your project is part of a larger organization or ecosystem, consider using a logo that aligns with that branding.</li> </ul>"},{"location":"configuration/table_of_contents/","title":"Table of Contents (ToC) Templates","text":"<p>README-AI offers flexible options for generating a Table of Contents (ToC) in your README file, directly from the command line. You can specify different styles of ToC generation using the <code>--toc-style</code> option when running the CLI.</p>"},{"location":"configuration/table_of_contents/#cli-usage-for-toc-styles","title":"CLI Usage for ToC Styles","text":"<p>When using the <code>readmeai</code> CLI, you can customize the Table of Contents by specifying one of the supported styles with the <code>--toc-style</code> flag.</p>"},{"location":"configuration/table_of_contents/#supported-toc-styles","title":"Supported ToC Styles:","text":"<ol> <li>Bullet (<code>bullet</code>)</li> <li> <p>Displays a simple bulleted list format for the Table of Contents.</p> </li> <li> <p>Fold (<code>fold</code>)</p> </li> <li> <p>Generates a collapsible Table of Contents. Users can click to expand the list of sections.</p> </li> <li> <p>Links (<code>links</code>)</p> </li> <li> <p>A quick link format that groups key sections under a \"Quick Links\" heading.</p> </li> <li> <p>Number (<code>number</code>)</p> </li> <li> <p>Numbers the sections in the Table of Contents for clear ordering and hierarchy.</p> </li> <li> <p>Roman (<code>roman</code>)</p> </li> <li>Uses Roman numerals to number the sections, providing a classic and formal appearance.</li> </ol>"},{"location":"configuration/table_of_contents/#example-cli-command","title":"Example CLI Command","text":"<p>Here\u2019s how to generate a README file with a Numbered Table of Contents:</p> <pre><code>readmeai --repository ./my_project --toc-style number --output README.md\n</code></pre> <p>In this example: - The <code>--repository</code> flag specifies the local project directory. - The <code>--toc-style number</code> flag sets the Table of Contents to use a numbered format. - The <code>--output README.md</code> flag specifies the output file name.</p>"},{"location":"configuration/table_of_contents/#another-example-with-foldable-toc","title":"Another Example with Foldable ToC","text":"<p>To generate a README with a Foldable Table of Contents, run:</p> <pre><code>readmeai --repository ./my_project --toc-style fold --output README.md\n</code></pre> <p>This will create a ToC that is hidden by default, allowing users to expand it if needed.</p>"},{"location":"configuration/table_of_contents/#available-toc-styles","title":"Available ToC Styles","text":"<pre><code>-tc, --toc-style [bullet|fold|links|number|roman]\n</code></pre> <p>The <code>--toc-style</code> option supports the following values:</p> <ul> <li>bullet: Simple bullet list</li> <li>fold: Collapsible ToC</li> <li>links: Quick links format</li> <li>number: Numbered list of sections</li> <li>roman: Roman numeral list of sections</li> </ul>"},{"location":"configuration/table_of_contents/#additional-customizations","title":"Additional Customizations","text":"<p>You can further customize your README file with options like header styles (<code>--header-style</code>), logo image (<code>--image</code>), and badges (<code>--badge-style</code>).</p>"},{"location":"examples/gallery/","title":"Example Gallery","text":"<p>Here are some examples of README files generated by readme-ai for various projects using different languages and frameworks.</p> Language/Framework Output File Input Repository Description Python readme-python.md readme-ai Core readme-ai project TypeScript &amp; React readme-typescript.md ChatGPT App React Native ChatGPT app PostgreSQL &amp; DuckDB readme-postgres.md Buenavista Postgres proxy server Kotlin &amp; Android readme-kotlin.md file.io Client Android file sharing app Streamlit readme-streamlit.md readme-ai-streamlit Streamlit UI for readme-ai app Rust &amp; C readme-rust-c.md CallMon System call monitoring tool Docker &amp; Go readme-go.md docker-gs-ping Dockerized Go app Java readme-java.md Minimal-Todo Minimalist todo Java app FastAPI &amp; Redis readme-fastapi-redis.md async-ml-inference Async ML inference service Jupyter Notebook readme-mlops.md mlops-course MLOps course repository Apache Flink readme-local.md Local Directory Example using a local directory <p><sub>See additional README files generated by readme-ai here</sub></p>"},{"location":"guides/markdown_best_practices/","title":"Markdown Best Practices","text":"<p>This document provides a comprehensive guide to writing technical documentation using the <code>GitHub flavored markdown spec</code>. This guide includes examples of how to use various markdown elements to create visually appealing and informative documentation.</p>"},{"location":"guides/markdown_best_practices/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Markdown Horizontal Rule</li> <li>HTML Horizontal Rule</li> <li>Table with Alignment<ul> <li>Multi-Line Table Cells</li> <li>Task Lists</li> <li>Merge Cells</li> </ul> </li> <li>Progress Bars</li> <li>Highlighting</li> <li>Underlining</li> <li>Keyboard Shortcuts<ul> <li>Navigating</li> <li>Editing</li> </ul> </li> <li>Centered Images</li> <li>Horizontally Aligned Images</li> <li>Small Images</li> <li>Text Boxes</li> <li>Text Wrapping</li> <li>Inline Links</li> <li>Reference Links</li> <li>Simple Contact</li> <li>Modern Contact with Social Icons</li> <li>Contributing Graph</li> </ul>"},{"location":"guides/markdown_best_practices/#line-separators","title":"Line Separators","text":""},{"location":"guides/markdown_best_practices/#markdown-horizontal-rule","title":"Markdown Horizontal Rule","text":"<pre><code>section end\n\n---\n</code></pre> <pre><code>section end\n\n***\n</code></pre>"},{"location":"guides/markdown_best_practices/#html-horizontal-rule","title":"HTML Horizontal Rule","text":"<pre><code>&lt;p&gt;section end&lt;/p&gt;\n\n&lt;hr&gt;\n</code></pre>"},{"location":"guides/markdown_best_practices/#lists","title":"Lists","text":"<p>Things I need to do today: 1. Fix usability problem 2. Clean up the page    * Make the headings bigger 2. Push my changes 3. Create code review    * Describe my changes    * Assign reviewers      * Ask for feedback</p>"},{"location":"guides/markdown_best_practices/#tables","title":"Tables","text":""},{"location":"guides/markdown_best_practices/#table-with-alignment","title":"Table with Alignment","text":"<pre><code>| Left Aligned | Centered | Right Aligned |\n| :---         | :---:    | ---:          |\n| Cell 1       | Cell 2   | Cell 3        |\n| Cell 4       | Cell 5   | Cell 6        |\n</code></pre> <p>This will render as:</p> Left Aligned Centered Right Aligned Cell 1 Cell 2 Cell 3 Cell 4 Cell 5 Cell 6"},{"location":"guides/markdown_best_practices/#multi-line-table-cells","title":"Multi-Line Table Cells","text":"<pre><code>| Name | Details |\n| ---  | ---     |\n| Item1 | This text is on one line |\n| Item2 | This item has:&lt;br&gt;- Multiple items&lt;br&gt;- That we want listed separately |\n</code></pre> <p>This will render as:</p> Name Details Item1 This text is on one line Item2 This item has:- Multiple items- That we want listed separately"},{"location":"guides/markdown_best_practices/#task-lists","title":"Task Lists","text":"<pre><code>| header 1 | header 2 |\n| ---      | ---      |\n| cell 1   | cell 2   |\n| cell 3   | &lt;ul&gt;&lt;li&gt; - [ ] Task one &lt;/li&gt;&lt;li&gt; - [ ] Task two &lt;/li&gt;&lt;/ul&gt; |\n</code></pre> <p>This will render as:</p> header 1 header 2 cell 1 cell 2 cell 3 <ul><li> - [ ] Task one </li><li> - [ ] Task two </li></ul>"},{"location":"guides/markdown_best_practices/#merge-cells","title":"Merge Cells","text":"<pre><code>&lt;table&gt;\n  &lt;tr&gt;\n    &lt;td colspan=\"2\"&gt;I take up two columns!&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;First column&lt;/td&gt;\n    &lt;td&gt;Second column&lt;/td&gt;\n  &lt;/tr&gt;\n&lt;/table&gt;\n</code></pre> <p>This will render as:</p> I take up two columns! First column Second column"},{"location":"guides/markdown_best_practices/#text-styling-formatting","title":"Text Styling &amp; Formatting","text":"<ul> <li>strikethrough or strikethrough</li> <li>H<sub>2</sub>O is a liquid and C<sub>6</sub>H<sub>12</sub>O<sub>6</sub> is a sugar.</li> <li>19<sup>th</sup></li> <li>X<sup>2</sup> + Y<sup>2</sup> = Z<sup>2</sup></li> <li>z<sup>2</sup> + c</li> <li> \u2003Install\u2003 </li> </ul>"},{"location":"guides/markdown_best_practices/#progress-bars","title":"Progress Bars","text":"<p>22%</p> <p>48%</p> <p>77%</p>"},{"location":"guides/markdown_best_practices/#highlighting","title":"Highlighting","text":"<p>highlighted text.</p>"},{"location":"guides/markdown_best_practices/#underlining","title":"Underlining","text":"<p>I'm Underlined!</p>"},{"location":"guides/markdown_best_practices/#buttons-keyboard-shortcuts","title":"Buttons &amp; Keyboard Shortcuts","text":"Click here Click here Or here Or here <p>Big Fat Button</p>"},{"location":"guides/markdown_best_practices/#keyboard-shortcuts","title":"Keyboard Shortcuts","text":"<p>Press Enter to go to the next page.</p>"},{"location":"guides/markdown_best_practices/#navigating","title":"Navigating","text":"<p>You can navigate through your items or search results using the keyboard. You can use Tab to cycle through results, and Shift + Tab to go backwards. Or use the arrow keys, \u2191, \u2192, \u2193 and \u2190.</p> <p>To copy the selected text, press Ctrl + C.</p>"},{"location":"guides/markdown_best_practices/#editing","title":"Editing","text":"<p>Press Ctrl + S to save your changes. Select text and press Ctrl + B to make it bold.</p>"},{"location":"guides/markdown_best_practices/#math-equations","title":"Math Equations","text":"\\[ \\begin{aligned} \\dot{x} &amp; = \\sigma(y-x) \\\\ \\dot{y} &amp; = \\rho x - y - xz \\\\ \\dot{z} &amp; = -\\beta z + xy \\end{aligned} \\] \\[ L = \\frac{1}{2} \\rho v^2 S C_L \\]"},{"location":"guides/markdown_best_practices/#images","title":"Images","text":""},{"location":"guides/markdown_best_practices/#simple-icons","title":"Simple Icons","text":""},{"location":"guides/markdown_best_practices/#docker","title":"Docker","text":""},{"location":"guides/markdown_best_practices/#docker_1","title":"Docker","text":""},{"location":"guides/markdown_best_practices/#centered-images","title":"Centered Images","text":""},{"location":"guides/markdown_best_practices/#horizontally-aligned-images","title":"Horizontally Aligned Images","text":""},{"location":"guides/markdown_best_practices/#small-images","title":"Small Images","text":"<p> Code documentation - Generated directory tree structure and summaries of the key files in your codebase.</p> <p> Spike documentation - Generated directory tree structure and summaries of the key files in your codebase.</p> <p> Chunking documentation - Generated directory tree structure and summaries of the key files in your codebase.</p>"},{"location":"guides/markdown_best_practices/#text-boxes","title":"Text Boxes","text":"<sub>This is text in the box. Much wow</sub>"},{"location":"guides/markdown_best_practices/#text-wrapping","title":"Text Wrapping","text":"<p>At the 2019 rendition of E3, an eccentric gamer in attendance interrupted Keanu Reeves' presentation of the role-playing game (RPG) Cyberpunk 2077, loudly claiming, \u201c\"You're breathtaking,\"\u201d which was directed at the actor-cum-presenter. The image macro used to build the \"You're Breathtaking\" meme generally features a still of Keanu Reeves pointing at someone in the audience in front of him - that someone is Peter Sark, though there are no images from Keanu's point of view that have since been used as part of the \"You're Breathtaking\" meme.</p>"},{"location":"guides/markdown_best_practices/#mermaid-diagrams","title":"Mermaid Diagrams","text":"<ul> <li>Mermaid Live Editor</li> </ul> <pre><code>graph TD;\n  A--&gt;B;\n  A--&gt;C;\n  B--&gt;D;\n  C--&gt;D;</code></pre> <pre><code>graph TB\n\n  SubGraph1 --&gt; SubGraph1Flow\n  subgraph \"SubGraph 1 Flow\"\n  SubGraph1Flow(SubNode 1)\n  SubGraph1Flow -- Choice1 --&gt; DoChoice1\n  SubGraph1Flow -- Choice2 --&gt; DoChoice2\n  end\n\n  subgraph \"Main Graph\"\n  Node1[Node 1] --&gt; Node2[Node 2]\n  Node2 --&gt; SubGraph1[Jump to SubGraph1]\n  SubGraph1 --&gt; FinalThing[Final Thing]\nend</code></pre> <pre><code>journey\n    title My working day\n    section Go to work\n      Make tea: 5: Me\n      Go upstairs: 3: Me\n      Do work: 1: Me, Cat\n    section Go home\n      Go downstairs: 5: Me\n      Sit down: 5: Me</code></pre> <pre><code>graph TD\nA[FastAPI Application] --&gt; B{HTTP Request}\nB --&gt; C{Request Validation}\nC -- Valid --&gt; D[Route Handler]\nC -- Invalid --&gt; E[RequestValidationError]\nD --&gt; F{Route Handler Execution}\nF -- Success --&gt; G[Response]\nF -- Exception --&gt; H{Exception Handling}\nH -- RequestError --&gt; I[request_error_handler]\nH -- HTTPException --&gt; J[http_exception_handler]\nH -- RequestValidationError --&gt; K[request_validation_error_handler]\nH -- Unhandled Exception --&gt; L[Internal Server Error]\nI --&gt; M[Custom Error Response]\nJ --&gt; N[HTTP Exception Response]\nK --&gt; O[Validation Error Response]\nL --&gt; P[Internal Server Error Response]\nM --&gt; Q[Return Response]\nN --&gt; Q\nO --&gt; Q\nP --&gt; Q</code></pre>"},{"location":"guides/markdown_best_practices/#return-to-top","title":"Return To Top","text":"<p>Return</p> <p>Return</p> <p>Return</p>"},{"location":"guides/markdown_best_practices/#html-spacing-entities","title":"HTML Spacing Entities","text":"Name HTML Entity Description En space <code>&amp;ensp;</code> Half the width of an em space Em space <code>&amp;emsp;</code> Width of an em space (equal to the font size) Three-per-em space <code>&amp;emsp13;</code> One-third of an em space Figure space <code>&amp;numsp;</code> Width of a numeral (digit) Punctuation space <code>&amp;puncsp;</code> Width of a period or comma Thin space <code>&amp;thinsp;</code> Thinner than a regular space Hair space <code>&amp;hairsp;</code> Thinner than a thin space Narrow no-break space <code>&amp;#8239;</code> Non-breaking thin space <p>Note: The <code>&amp;emsp13;</code> and <code>&amp;puncsp;</code> entities may not be supported in all browsers. For the narrow no-break space, there isn't a named HTML entity, so the numeric character reference <code>&amp;#8239;</code> is used.</p>"},{"location":"guides/markdown_best_practices/#links","title":"Links","text":""},{"location":"guides/markdown_best_practices/#inline-links","title":"Inline Links","text":"<p>inline link reference link</p>"},{"location":"guides/markdown_best_practices/#reference-links","title":"Reference Links","text":"<p>reference link 2</p>"},{"location":"guides/markdown_best_practices/#contact","title":"Contact","text":""},{"location":"guides/markdown_best_practices/#simple-contact","title":"Simple Contact","text":"<p>If you have any questions or comments, feel free to reach out to me! - Email: your-email@example.com - Twitter: @YourHandle</p>"},{"location":"guides/markdown_best_practices/#modern-contact-with-social-icons","title":"Modern Contact with Social Icons","text":"<p> <sub>     For readme-ai issues and feature requests please visit our issues page, or start a discussion! </sub> </p>"},{"location":"guides/markdown_best_practices/#contributing-guidelines","title":"Contributing Guidelines","text":""},{"location":"guides/markdown_best_practices/#contributing-graph","title":"Contributing Graph","text":""},{"location":"guides/markdown_best_practices/#references","title":"References","text":"<ul> <li>github-markdown-tricks</li> </ul>"},{"location":"guides/markdown_best_practices/#footnotes","title":"Footnotes","text":"<p>Here's a sample sentence with a footnote.[^1]</p> <p>[^1]: And here's the definition of the footnote.</p>"},{"location":"llms/","title":"Large Language Model (LLM) Integrationss","text":"<p>Readme-ai integrates seamlessly with various Large Language Model (LLM) services to generate high-quality README content. This page provides an overview of the supported LLM services and links to detailed information about each.</p>"},{"location":"llms/#supported-llm-services","title":"Supported LLM Services","text":"<ol> <li>OpenAI</li> <li>Ollama</li> <li>Anthropic</li> <li>Google Gemini</li> <li>Offline Mode</li> </ol>"},{"location":"llms/#comparing-llm-services","title":"Comparing LLM Services","text":"Service Pros Cons OpenAI High-quality output, Versatile Requires API key, Costs associated Ollama Free, Privacy-focused, Offline May be slower, Requires local setup Anthropic Privacy-focused, Offline May be slower, Requires local setup Gemini Strong performance, Google integration Requires API key Offline No internet required, Fast Basic output, Limited customization"},{"location":"llms/#tips-for-optimal-results","title":"Tips for Optimal Results","text":"<ol> <li>Experiment with different models: Try various LLM services and models to find the best fit for your project.</li> <li>Provide clear context: Ensure your repository has well-organized code and documentation to help the LLM generate more accurate content.</li> <li>Fine-tune with CLI options: Use readme-ai's CLI options to customize the output further after choosing your LLM service.</li> <li>Review and edit: Always review the generated README and make necessary edits to ensure accuracy and relevance to your project.</li> </ol> <p>By leveraging these LLM integrations effectively, you can generate comprehensive and accurate README files for your projects with minimal effort. Here is a structured content tab implementation for integrating multiple APIs in README-AI, based on the detailed API integration information you provided:</p>"},{"location":"llms/#api-integrations","title":"\ud83d\ude80 API Integrations","text":"<p>README-AI supports multiple large language model (LLM) APIs for generating README files. The following tabs explain how to configure and use each supported API.</p>"},{"location":"llms/#api-configuration-tabs","title":"API Configuration Tabs","text":"AnthropicGeminiOllamaOpenAIOfflineMode <pre><code>```sh\nreadmeai --api anthropic --model claude-3-opus-20240229 --repository &lt;REPO_URL_OR_PATH&gt;\n```\n</code></pre> <pre><code>```sh\nreadmeai --api gemini --model gemini-1.5-flash --repository &lt;REPO_URL_OR_PATH&gt;\n```\n</code></pre> <pre><code>```sh\nreadmeai --api ollama --model llama3 --repository &lt;REPO_URL_OR_PATH&gt;\n```\n</code></pre> <pre><code>```sh\nreadmeai --api openai --model gpt-3.5-turbo --repository &lt;REPO_URL_OR_PATH&gt;\n```\n</code></pre> <pre><code>```sh\nreadmeai --api offline --repository &lt;REPO_URL_OR_PATH&gt;\n```\n</code></pre> <p>```</p>"},{"location":"llms/anthropic/","title":"Installation Guide for readme-ai with Ollama","text":"<p>Get started with readme-ai using Ollama. This guide will show you how to install and run readme-ai using Ollama in your local environment.</p> Ollama Requirement <p>Ensure you have Ollama installed and running on your system. For the latest installation guide, visit the Ollama GitHub repository.</p>"},{"location":"llms/anthropic/#installation-using-ollama","title":"Installation Using Ollama","text":"<p>To use readme-ai with Ollama, follow these steps:</p> <ol> <li>Install Ollama</li> </ol> <p>Ensure you have installed Ollama on your system. You can find detailed installation instructions on the Ollama GitHub page.</p> <ol> <li>Pull the LLM Model</li> </ol> <p>Pull the required LLM model to use with Ollama:</p> <pre><code>ollama pull llama3:latest\n</code></pre> <ol> <li>Start the Ollama Server</li> </ol> <p>Start the Ollama server locally:</p> <pre><code>export OLLAMA_HOST=127.0.0.1 &amp;&amp; ollama serve\n</code></pre> <ol> <li>Run readme-ai with Ollama</li> </ol> <p>After starting the server, run readme-ai with Ollama:</p> <pre><code>readmeai --api ollama --model llama3 --repository https://github.com/eli64s/readme-ai\n</code></pre> <p>Explanation of common arguments:</p> Argument Description <code>--api</code> Specifies the LLM API service to use (in this case, Ollama). <code>--model</code> Specifies the model to use with Ollama (e.g., llama3). <code>--repository</code> Specifies the GitHub repository or local directory path to analyze."},{"location":"llms/anthropic/#optional-dependencies","title":"Optional Dependencies","text":"<p>To use additional LLM providers like Anthropic or Google Gemini in addition to Ollama, install the optional dependencies:</p> <p>Anthropic:</p> <pre><code>pip install readmeai[anthropic]\n</code></pre> <p>Google Gemini:</p> <pre><code>pip install readmeai[gemini]\n</code></pre>"},{"location":"llms/anthropic/#usage","title":"Usage","text":""},{"location":"llms/anthropic/#setting-environment-variables","title":"Setting Environment Variables","text":"<p>Ollama Host</p> <p>Set the Ollama host to enable the local server:</p> <pre><code>export OLLAMA_HOST=127.0.0.1\n</code></pre> <p>For Windows users, use:</p> <pre><code>set OLLAMA_HOST=127.0.0.1\n</code></pre>"},{"location":"llms/anthropic/#running-readme-ai-with-ollama","title":"Running readme-ai with Ollama","text":"<p>Run readme-ai with the Ollama model:</p> <pre><code>readmeai --api ollama --model llama3 --repository https://github.com/eli64s/readme-ai\n</code></pre> <p>For a list of all available options, run:</p> <pre><code>readmeai --help\n</code></pre>"},{"location":"llms/anthropic/#troubleshooting","title":"Troubleshooting","text":"<ol> <li>Server Connection Issues: Ensure that the Ollama server is running and accessible. Verify that the host address is set correctly.</li> <li>Model Not Found: Make sure that the required LLM model is properly pulled using the <code>ollama pull</code> command.</li> <li>Permission Issues: Ensure you have the necessary permissions to run commands with Ollama. You may need administrative rights on your system.</li> </ol> <p>For further help, you can open an issue on GitHub or refer to the official documentation.</p>"},{"location":"llms/google_gemini/","title":"Google Gemini","text":"<p>Google's Gemini models offer strong performance across a wide range of tasks.</p>"},{"location":"llms/google_gemini/#configuration","title":"Configuration","text":"<pre><code>readmeai --repository &lt;REPO_URL_OR_PATH&gt; --api gemini --model gemini-1.5-flash\n</code></pre>"},{"location":"llms/google_gemini/#available-models","title":"Available Models","text":"<p>It is recommended to use the following models:</p> <ul> <li><code>gemini-1.5-pro</code></li> </ul>"},{"location":"llms/google_gemini/#best-practices","title":"Best Practices","text":"<ul> <li>Gemini models excel at understanding context and generating coherent text.</li> <li>Ensure you have the necessary API credentials set up.</li> </ul>"},{"location":"llms/offline_mode/","title":"Offline Mode","text":"<p>Offline mode allows you to generate a README without an internet connection. This is useful when you want to quickly generate boilerplate README files.</p>"},{"location":"llms/offline_mode/#configuration","title":"Configuration","text":"<pre><code>readmeai --api offline -r https://github.com/username/project\n</code></pre>"},{"location":"llms/offline_mode/#offline-mode-readme-example","title":"Offline Mode README Example","text":"<ul> <li>readme-offline-mode.md</li> </ul> Note <ul> <li>Use offline mode for quick boilerplate generation or when you don't have internet access.</li> <li>Customize the generated README manually after generation.</li> </ul>"},{"location":"llms/ollama/","title":"Ollama","text":"<p>Ollama is a privacy-focused, open-source tool for running open-source LLMs locally such as <code>Llama 3</code>, <code>Mistral</code>, and <code>Gemma 2</code>. Ollama can be used with readme-ai to generate README files with a variety of models and configurations from their model library.</p>"},{"location":"llms/ollama/#usage","title":"Usage","text":"<p>Start by downloading Ollama, and then pull a model such as Llama 3 or Mistral.</p> <pre><code>ollama pull llama3\n</code></pre> <p>Once you have the model, run the ollama server.</p> <pre><code>ollama run llama3\n</code></pre> <p>Then, you can use the <code>readmeai</code> CLI to generate README files using the Ollama API.</p> <pre><code>readmeai --api ollama --model llama3 -r https//github.com/username/project\n</code></pre> Note <ul> <li>Slower README generation times may be experienced when using Ollama compared to cloud-based services.</li> </ul>"},{"location":"llms/openai/","title":"OpenAI","text":"<p>OpenAI's GPT models are known for their versatility and high-quality text generation.</p>"},{"location":"llms/openai/#configuration","title":"Configuration","text":"<pre><code>readmeai --repository &lt;REPO_URL_OR_PATH&gt; --api openai --model gpt-3.5-turbo\n</code></pre>"},{"location":"llms/openai/#available-models","title":"Available Models","text":"<p>Although not limited to the following, it is recommended to use the following models: - <code>gpt-3.5-turbo</code> - <code>gpt-4</code> - <code>gpt-4-turbo</code></p>"},{"location":"llms/openai/#best-practices","title":"Best Practices","text":"<ul> <li>Use <code>gpt-3.5-turbo</code> for faster generation and lower costs.</li> <li>Use <code>gpt-4</code> or <code>gpt-4-turbo</code> for more complex projects or when you need higher accuracy.</li> </ul>"},{"location":"quickstart/installation/","title":"Installation","text":"<p>Install <code>readmeai</code> using one of the following methods:</p>"},{"location":"quickstart/installation/#pip","title":"Pip","text":"<p>Pip is the default Python package manager and recommended for installing <code>readmeai</code>:</p> <pre><code>pip install readmeai\n</code></pre>"},{"location":"quickstart/installation/#pipx","title":"Pipx","text":"<p>Alternatively, use <code>pipx</code> to install <code>readmeai</code> in an isolated environment:</p> <pre><code>pipx install readmeai\n</code></pre> Why use pipx? <p>Using <code>pipx</code> allows you to install and run Python command-line applications in isolated environments, which helps prevent dependency conflicts with other Python projects.</p>"},{"location":"quickstart/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>To use additional LLM providers like Anthropic or Google Gemini, install the optional dependencies:</p> <p>Anthropic:</p> <pre><code>pip install \"readmeai[anthropic]\"\n</code></pre> <p>Google Gemini:</p> <pre><code>pip install pip install \"readmeai[google-generativeai]\"\n</code></pre> <p>For usage instructions, see the Usage section.</p>"},{"location":"quickstart/prerequisites/","title":"Prerequisites","text":""},{"location":"quickstart/prerequisites/#system-requirements","title":"System Requirements","text":"<ul> <li>Python: <code>3.9</code> or higher.</li> <li>Package Manage/Container: <code>pip</code>, <code>pipx</code>, or <code>docker</code>.</li> </ul>"},{"location":"quickstart/prerequisites/#repository-or-directory","title":"Repository or Directory","text":"<p>A Git repository or a local file system directory is required to generate a README file. Supported platforms include:</p> <ul> <li>GitHub</li> <li>GitLab</li> <li>Bitbucket</li> <li>File System</li> </ul> <p><sub>If your Git provider is not listed, open an issue or submit a pull request to add support for additional platforms.</sub></p>"},{"location":"quickstart/prerequisites/#llm-api-key","title":"LLM API Key","text":"<p>To enable the full functionality of <code>readmeai</code>, an account and API key are required for one of the following providers:</p> <ul> <li>OpenAI: OpenAI API</li> <li>Ollama: Ollama API</li> <li>Anthropic: Anthropic API</li> <li>Google Gemini: Google Gemini API</li> <li>Offline Mode: Runs <code>readmeai</code> offline, or without an API key.</li> </ul> <p><sub>For more information on setting up an API key, refer to the provider's documentation.</sub></p>"},{"location":"usage/cli/","title":"CLI Usage","text":"<p>This guide covers the basic usage of readme-ai and provides examples for different LLM services.</p>"},{"location":"usage/cli/#basic-usage","title":"Basic Usage","text":"<p>The general syntax for using readme-ai is:</p> <pre><code>readmeai --repository &lt;REPO_URL_OR_PATH&gt; --api &lt;LLM_SERVICE&gt; [OPTIONS]\n</code></pre> <p>Replace <code>&lt;REPO_URL_OR_PATH&gt;</code> with your repository URL or local path, and <code>&lt;LLM_SERVICE&gt;</code> with your chosen LLM service (openai, ollama, gemini, or offline).</p>"},{"location":"usage/cli/#examples","title":"Examples","text":""},{"location":"usage/cli/#using-openai","title":"Using OpenAI","text":"<pre><code>readmeai --repository https://github.com/eli64s/readme-ai \\\n         --api openai \\\n         --model gpt-3.5-turbo # (1)\n</code></pre> <ol> <li> Model currently defaults to <code>gpt-3.5-turbo</code></li> </ol>"},{"location":"usage/cli/#using-ollama","title":"Using Ollama","text":"<pre><code>readmeai --repository https://github.com/eli64s/readme-ai \\\n         --api ollama \\\n         --model llama3\n</code></pre>"},{"location":"usage/cli/#using-google-gemini","title":"Using Google Gemini","text":"<pre><code>readmeai --repository https://github.com/eli64s/readme-ai \\\n         --api gemini \\\n         --model gemini-1.5-flash\n</code></pre>"},{"location":"usage/cli/#offline-mode","title":"Offline Mode","text":"<pre><code>readmeai --repository https://github.com/eli64s/readme-ai \\\n         --api offline\n</code></pre>"},{"location":"usage/cli/#advanced-usage","title":"Advanced Usage","text":"<p>You can customize the output using various options:</p> <pre><code>readmeai --repository https://github.com/eli64s/readme-ai \\\n         --output readmeai.md \\\n         --api openai \\\n         --model gpt-4-turbo \\\n         --badge-color A931EC \\\n         --badge-style flat-square \\\n         --header-style compact \\\n         --toc-style fold \\\n         --temperature 0.1 \\\n         --tree-depth 2 \\\n         --image LLM \\\n         --emojis\n</code></pre> <p>For a full list of options, run:</p> <pre><code>readmeai --help\n</code></pre> <p>See the Configuration Options documentation for detailed explanations of each option.</p>"},{"location":"usage/cli/#tips-for-effective-usage","title":"Tips for Effective Usage","text":"<ol> <li>Choose the right LLM: Different LLMs may produce varying results. Experiment to find the best fit for your project.</li> <li>Adjust temperature: Lower values (e.g., 0.1) produce more focused output, while higher values (e.g., 0.8) increase creativity.</li> <li>Use custom prompts: For specialized projects, consider using custom prompts to guide the AI's output.</li> <li>Review and edit: Always review the generated README and make necessary adjustments to ensure accuracy and relevance.</li> </ol>"},{"location":"usage/cli/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter any issues:</p> <ol> <li>Ensure you have the latest version of readme-ai installed.</li> <li>Check your API credentials if using OpenAI or Google Gemini.</li> <li>For Ollama, make sure the Ollama service is running locally.</li> <li>Consult the FAQ or open an issue for additional support.</li> </ol>"},{"location":"usage/docker/","title":"Docker","text":"<p>Running readme-ai in a containerized environment using Docker offers isolation of the application and its dependencies from the host system. This section details how to pull the Docker image from Docker Hub, build the Docker image from the source code, and run the Docker container.</p> Docker Installation <p>Before proceeding, ensure that Docker is installed and running on your system. If you haven't installed Docker yet, please visit the official Docker documentation for installation instructions.</p>"},{"location":"usage/docker/#pull-the-docker-image","title":"Pull the Docker Image","text":"<p>Pull the latest readme-ai image from Docker Hub:</p> <pre><code>docker pull zeroxeli/readme-ai:latest\n</code></pre>"},{"location":"usage/docker/#build-the-docker-image","title":"Build the Docker Image","text":"<p>Alternatively, you can build the Docker image from the source code. This assumes you have cloned the readme-ai repository.</p> <pre><code>docker buildx build --platform linux/amd64,linux/arm64 -t readme-ai --push .\n</code></pre> Buildx <p>Using <code>docker buildx</code> allows you to build multi-platform images, which means you can create Docker images that work on different architectures (e.g., amd64 and arm64). This is particularly useful if you want your Docker image to be compatible with a wider range of devices and environments, such as both standard servers and ARM-based devices like the Raspberry Pi.</p>"},{"location":"usage/docker/#run-the-docker-container","title":"Run the Docker Container","text":"<p>Run the readme-ai Docker container with the following command:</p> <pre><code>docker run -it --rm \\\n-e OPENAI_API_KEY=$OPENAI_API_KEY \\\n-v \"$(pwd)\":/app zeroxeli/readme-ai:latest \\\n-r https://github.com/eli64s/readme-ai \\\n--api openai\n</code></pre> <p>Explanation of the command arguments:</p> Argument Function <code>-it</code> Creates an interactive terminal. <code>--rm</code> Automatically removes the container when it exits. <code>-e</code> Passes your OpenAI API key as an environment variable. <code>-v \"$(pwd)\":/app</code> Mounts the current directory to the <code>/app</code> directory in the container, allowing access to the generated README file on your host system. <code>-r</code> Specifies the GitHub repository to analyze. <p>For Windows users, replace <code>$(pwd)</code> with <code>%cd%</code> in the command. For PowerShell, use <code>${PWD}</code> instead.</p>"},{"location":"usage/docker/#cleanup","title":"Cleanup","text":"<p>If you want to remove the Docker image and container from your system, follow these steps.</p> <p>1. Identify the Container</p> <p>First, list all containers on your system.</p> <pre><code>docker ps -a\n</code></pre> <p>You should see output similar to the following:</p> <pre><code>CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS     NAMES\nabcdef123456   zeroxeli/readme-ai:latest   \"python main.py -r h\u2026\"   2 minutes ago    Up 2 minutes\n</code></pre> <p>Look for the container with ID <code>abcdef123456</code>.</p> <p>2. Stop the Container</p> <p>Stop the container using its ID.</p> <pre><code>docker stop abcdef123456\n</code></pre> <p>3. Remove the Container</p> <p>Remove the container using its ID.</p> <pre><code>docker rm abcdef123456\n</code></pre> <p>4. Remove the Image</p> <p>Remove the Docker image from your system.</p> <pre><code>docker rmi zeroxeli/readme-ai:latest\n</code></pre>"},{"location":"usage/docker/#troubleshooting","title":"Troubleshooting","text":"<ol> <li>If you encounter permission issues, ensure your user has the right permissions to run Docker commands.</li> <li>If the container fails to start, check that your <code>OPENAI_API_KEY</code> is correctly set and valid.</li> <li>For network-related issues, verify your internet connection and firewall settings.</li> </ol> <p>For more detailed troubleshooting, refer to the official Docker documentation or open an issue on GitHub.</p>"},{"location":"usage/pip/","title":"Pip","text":"<p>After installation, you can run readme-ai with:</p> <pre><code>readmeai --api openai --repository https://github.com/eli64s/readme-ai\n</code></pre>"},{"location":"usage/pip/#usage","title":"Usage","text":""},{"location":"usage/pip/#setting-environment-variables","title":"Setting Environment Variables","text":"<p>OpenAI API Key</p> <p>Generate an OpenAI API key and set it as an environment variable:</p> <pre><code>export OPENAI_API_KEY=&lt;your_api_key&gt;\n</code></pre> <p>For Windows users, use:</p> <pre><code>set OPENAI_API_KEY=&lt;your_api_key&gt;\n</code></pre> <p>Anthropic API Key</p> <p>To use the Anthropic API, set your API key:</p> <pre><code>export ANTHROPIC_API_KEY=&lt;your_api_key&gt;\n</code></pre>"},{"location":"usage/pip/#running-readme-ai","title":"Running readme-ai","text":"<p>Run readme-ai with OpenAI:</p> <pre><code>readmeai --api openai --repository https://github.com/eli64s/readme-ai\n</code></pre> <p>Run readme-ai with Anthropic:</p> <pre><code>readmeai --api anthropic --repository https://github.com/eli64s/readme-ai\n</code></pre> <p>For a list of all available options, run:</p> <pre><code>readmeai --help\n</code></pre>"},{"location":"usage/pip/#troubleshooting","title":"Troubleshooting","text":"<ol> <li>Permission Issues: Ensure you have the necessary permissions to install Python packages. You may need to use <code>sudo</code> on Unix-based systems.</li> <li>Pipx Not Found: Make sure <code>pipx</code> is properly installed and available in your PATH. You can find installation instructions here.</li> <li>Missing Dependencies: Some advanced features require additional Python packages. Check the official documentation for a list of optional dependencies.</li> </ol> <p>For further help, you can open an issue on GitHub or refer to the official documentation.</p>"},{"location":"usage/streamlit/","title":"Streamlit","text":"<p>Run readme-ai directly in your browser on Streamlit Cloud. No installation required!</p> <p></p> <p>Source Code</p> <p>Find the source code for the Streamlit app in the readme-ai repository</p>"}]}