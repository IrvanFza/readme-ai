{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Readme-ai","text":"<p>Readme-ai is an automated README file generator powered by large language model APIs. It streamlines documentation creation and maintenance, enhancing developer productivity across all skill levels and domains.</p>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Installation</li> <li>Usage</li> <li>Features</li> <li>Examples</li> <li>Contributing</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Flexible README Generation: Robust repository context extraction combined with generative AI.</li> <li>Multiple LLM Support: Compatible with OpenAI, Ollama, Google Gemini, and Offline Mode.</li> <li>Customizable Output: Dozens of CLI options for styling, badges, header designs, and more.</li> <li>Language Agnostic: Works with a wide range of programming languages and project types.</li> <li>Offline Mode: Generate a boilerplate README without calling an external API.</li> </ul> <p>For more information on getting started, check out our Installation and Usage guides.</p>"},{"location":"configuration/","title":"Configuration","text":"<p>Readme-ai offers a wide range of configuration options to customize your README generation. This page provides a comprehensive list of all available options with detailed explanations.</p>"},{"location":"configuration/#cli-options","title":"CLI Options","text":"Option Description Default Impact <code>--align</code> Text alignment in header <code>center</code> Affects the visual layout of the README header <code>--api</code> LLM API service <code>offline</code> Determines which AI service is used for content generation <code>--badge-color</code> Badge color (name or hex) <code>0080ff</code> Customizes the color of status badges in the README <code>--badge-style</code> Badge icon style type <code>flat</code> Changes the visual style of status badges <code>--base-url</code> Base URL for the repository <code>v1/chat/completions</code> Used for API requests to the chosen LLM service <code>--context-window</code> Max context window of LLM API <code>3999</code> Limits the amount of context provided to the LLM <code>--emojis</code> Add emojis to README sections <code>False</code> Adds visual flair to section headers <code>--header-style</code> Header template style <code>default</code> Changes the overall look of the README header <code>--image</code> Project logo image <code>blue</code> Sets the main image displayed in the README <code>--model</code> Specific LLM model to use <code>gpt-3.5-turbo</code> Chooses the AI model for content generation <code>--output</code> Output filename <code>readme-ai.md</code> Specifies the name of the generated README file <code>--rate-limit</code> Max API requests per minute <code>5</code> Prevents exceeding API rate limits <code>--repository</code> Repository URL or local path <code>None</code> Specifies the project to analyze <code>--temperature</code> Creativity level for generation <code>0.9</code> Controls the randomness of the AI's output <code>--toc-style</code> Table of contents style <code>bullets</code> Changes the format of the table of contents <code>--top-p</code> Top-p sampling probability <code>0.9</code> Fine-tunes the AI's output diversity <code>--tree-depth</code> Max depth of directory tree <code>2</code> Controls the detail level of the project structure"},{"location":"configuration/#detailed-option-explanations","title":"Detailed Option Explanations","text":""},{"location":"configuration/#-api","title":"--api","text":"<ul> <li>Options: <code>openai</code>, <code>ollama</code>, <code>gemini</code>, <code>offline</code></li> <li>Impact: Determines the AI service used for generating README content. Each service has its own strengths and may produce slightly different results.</li> </ul>"},{"location":"configuration/#-badge-style","title":"--badge-style","text":"<ul> <li>Options: <code>default</code>, <code>flat</code>, <code>flat-square</code>, <code>for-the-badge</code>, <code>plastic</code>, <code>skills</code>, <code>skills-light</code>, <code>social</code></li> <li>Impact: Changes the visual appearance of status badges in the README. Different styles can better match your project's aesthetic.</li> </ul>"},{"location":"configuration/#-header-style","title":"--header-style","text":"<ul> <li>Options: <code>default</code>, <code>classic</code>, <code>modern</code>, <code>compact</code></li> <li>Impact: Alters the layout and design of the README header, including how the project title, description, and badges are displayed.</li> </ul>"},{"location":"configuration/#-image","title":"--image","text":"<ul> <li>Options: <code>blue</code>, <code>gradient</code>, <code>black</code>, <code>cloud</code>, <code>purple</code>, <code>grey</code>, <code>custom</code>, <code>llm</code></li> <li>Impact: Sets the main visual element of your README. Using <code>custom</code> allows you to specify your own image, while <code>llm</code> generates an image using AI.</li> </ul>"},{"location":"configuration/#-model","title":"--model","text":"<ul> <li>Options vary by API service</li> <li>Impact: Different models have varying capabilities and may produce different quality or style of content. Higher-tier models (e.g., GPT-4) generally produce better results but may be slower or more expensive.</li> </ul>"},{"location":"configuration/#-temperature","title":"--temperature","text":"<ul> <li>Range: 0.0 to 1.0</li> <li>Impact: Lower values produce more focused and deterministic output, while higher values increase creativity and randomness.</li> </ul>"},{"location":"configuration/#-toc-style","title":"--toc-style","text":"<ul> <li>Options: <code>bullets</code>, <code>numbers</code>, <code>fold</code></li> <li>Impact: Changes how the table of contents is formatted. The <code>fold</code> option creates a collapsible ToC, which can be useful for longer READMEs.</li> </ul>"},{"location":"configuration/#best-practices","title":"Best Practices","text":"<ol> <li>Start with defaults: Begin with the default options and gradually customize to find the best fit for your project.</li> <li>Match your project's style: Use badge and header styles that complement your project's branding or purpose.</li> <li>Balance detail and brevity: Adjust <code>tree-depth</code> based on your project's complexity. Deeper trees provide more detail but can make the README lengthy.</li> <li>Experiment with LLM settings: Try different combinations of <code>temperature</code> and <code>top-p</code> to find the right balance of creativity and coherence.</li> <li>Consider API usage: If using paid API services, be mindful of <code>rate-limit</code> and choose models that balance quality and cost.</li> </ol> <p>By carefully configuring these options, you can generate READMEs that are not only informative but also visually appealing and perfectly tailored to your project's needs.</p>"},{"location":"contributing/","title":"Contributing Guidelines","text":"<p>Thanks for your interest in contributing to readme-ai. Please review these guidelines to ensure a smooth process.</p>"},{"location":"contributing/#make-valuable-contributions","title":"Make Valuable Contributions","text":"<p>Strive to make useful, creative, and high quality contributions. This isn't meant to be a high bar, but more of a guiding principle and philosophy. Here's what we mean by these terms:</p> <p>Useful: Solve common problems, use cases, bugs, or new features.</p> <p>Creative: Innovative and helping us all grow and learn new things.</p> <p>High Quality: Well-written, structured, and explained.</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to Contribute","text":"<p>To improve and grow the project, we need your help! Here are some ways to get involved:</p> Activity Ideas \ud83d\udc4b Discussions Start a discussion by asking a question or making a suggestion. \ud83d\udc1b Open an Issue Find unhandled exceptions and bugs in the codebase. \ud83d\udcc4 Documentation Write documentation for the project. \ud83e\uddea Testing Write unit tests to increase code coverage. \ud83e\udde9 Feature Requests Brainstorm new ideas such as a CLI option to select any language. \ud83d\udee0\ufe0f Code Contributions Contribute to the codebase and submit a pull request. \ud83d\udd22 Code Readability Find ways to make code more readable and easier to understand. \ud83e\udd14 Other Anything else you can think of! <p>These are just a few examples, and we welcome any other ideas you may have!</p>"},{"location":"contributing/#submitting-changes","title":"Submitting Changes","text":"<ol> <li>Fork the repository and clone it locally.</li> <li>Create a new branch with a descriptive name i.e <code>feature/new-feature-name</code> or <code>bugfix-issue-123</code>.</li> <li>Make focused changes with clear commits.</li> <li>Open a pull request document the changes you've made and why they're necessary.</li> <li>Respond to code reviews from maintainers.</li> </ol>"},{"location":"contributing/#code-quality-expectations","title":"Code Quality Expectations","text":"<ul> <li>Clear, well-documented code</li> <li>Include tests for new code</li> <li>Follow project style standards</li> <li>Rebase onto latest main branch</li> </ul>"},{"location":"contributing/#attribution","title":"Attribution","text":"<p>Contributors to our project will be acknowledged in the project's README.md file.</p>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing to our project, you agree to license your contributions under the project's open source license. The project's license can be found in the LICENSE</p> <p>Thank you for your interest in contributing to readme-ai! We appreciate your help and look forward to working with you.</p>"},{"location":"examples/","title":"Basic Usage Examples","text":"<p>This page provides simple examples of using readme-ai with different LLM services and basic configurations.</p>"},{"location":"examples/#generate-readme-with-openai","title":"Generate README with OpenAI","text":"<pre><code>readmeai --repository https://github.com/username/project \\\n         --api openai \\\n         --model gpt-3.5-turbo\n</code></pre>"},{"location":"examples/#generate-readme-with-ollama","title":"Generate README with Ollama","text":"<pre><code>readmeai --repository https://github.com/username/project \\\n         --api ollama \\\n         --model mistral\n</code></pre>"},{"location":"examples/#generate-readme-with-google-gemini","title":"Generate README with Google Gemini","text":"<pre><code>readmeai --repository https://github.com/username/project \\\n         --api gemini\n</code></pre>"},{"location":"examples/#generate-readme-in-offline-mode","title":"Generate README in Offline Mode","text":"<pre><code>readmeai --repository https://github.com/username/project \\\n         --api offline\n</code></pre>"},{"location":"examples/#customize-badge-style-and-color","title":"Customize Badge Style and Color","text":"<pre><code>readmeai --repository https://github.com/username/project \\\n         --api openai \\\n         --badge-style flat-square \\\n         --badge-color \"#FF5733\"\n</code></pre>"},{"location":"examples/#use-custom-project-logo","title":"Use Custom Project Logo","text":"<pre><code>readmeai --repository https://github.com/username/project \\\n         --api openai \\\n         --image custom\n</code></pre> <p>When prompted, enter the path or URL to your custom logo image.</p>"},{"location":"examples/#generate-readme-with-emojis","title":"Generate README with Emojis","text":"<pre><code>readmeai --repository https://github.com/username/project \\\n         --api openai \\\n         --emojis\n</code></pre> <p>These examples demonstrate basic usage of readme-ai. For more advanced configurations and options, see the Advanced Configurations page.</p>"},{"location":"installation/","title":"Installation","text":"<p>Readme-ai can be installed using several methods. Choose the one that best fits your workflow.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9+</li> <li>Package manager/Container: <code>pip</code>, <code>pipx</code>, <code>docker</code></li> </ul>"},{"location":"installation/#using-pip","title":"Using pip","text":"<pre><code>pip install readmeai\n</code></pre>"},{"location":"installation/#using-pipx","title":"Using pipx","text":"<p>pipx is recommended for installing Python CLI applications:</p> <pre><code>pipx install readmeai\n</code></pre>"},{"location":"installation/#using-docker","title":"Using Docker","text":"<pre><code>docker pull zeroxeli/readme-ai:latest\n</code></pre>"},{"location":"installation/#from-source","title":"From source","text":"<ol> <li> <p>Clone the repository:    <code>sh    git clone https://github.com/eli64s/readme-ai    cd readme-ai</code></p> </li> <li> <p>Install using one of the following methods:</p> </li> </ol> <p>Using bash:    <code>sh    bash setup/setup.sh</code></p> <p>Using poetry:    <code>sh    poetry install</code></p> <p>After installation, verify that readme-ai is correctly installed by running:</p> <pre><code>readmeai --version\n</code></pre> <p>For usage instructions, see the Usage guide.</p>"},{"location":"llm-integrations/","title":"LLM Integration","text":"<p>Readme-ai integrates seamlessly with various Large Language Model (LLM) services to generate high-quality README content. This page details the supported LLM services and how to use them effectively.</p>"},{"location":"llm-integrations/#supported-llm-services","title":"Supported LLM Services","text":""},{"location":"llm-integrations/#1-openai","title":"1. OpenAI","text":"<p>OpenAI's GPT models are known for their versatility and high-quality text generation.</p>"},{"location":"llm-integrations/#configuration","title":"Configuration:","text":"<pre><code>readmeai --api openai --model gpt-3.5-turbo\n</code></pre>"},{"location":"llm-integrations/#available-models","title":"Available Models:","text":"<ul> <li><code>gpt-3.5-turbo</code></li> <li><code>gpt-4</code></li> <li><code>gpt-4-turbo</code></li> </ul>"},{"location":"llm-integrations/#best-practices","title":"Best Practices:","text":"<ul> <li>Use <code>gpt-3.5-turbo</code> for faster generation and lower costs.</li> <li>Use <code>gpt-4</code> or <code>gpt-4-turbo</code> for more complex projects or when you need higher accuracy.</li> </ul>"},{"location":"llm-integrations/#2-ollama","title":"2. Ollama","text":"<p>Ollama provides locally-run, open-source language models.</p>"},{"location":"llm-integrations/#configuration_1","title":"Configuration:","text":"<pre><code>readmeai --api ollama --model llama2\n</code></pre>"},{"location":"llm-integrations/#available-models_1","title":"Available Models:","text":"<ul> <li><code>llama2</code></li> <li><code>mistral</code></li> <li><code>gemma</code></li> </ul>"},{"location":"llm-integrations/#best-practices_1","title":"Best Practices:","text":"<ul> <li>Ensure Ollama is running locally before using this option.</li> <li>Ollama models run offline, providing privacy and speed benefits.</li> </ul>"},{"location":"llm-integrations/#3-google-gemini","title":"3. Google Gemini","text":"<p>Google's Gemini models offer strong performance across a wide range of tasks.</p>"},{"location":"llm-integrations/#configuration_2","title":"Configuration:","text":"<pre><code>readmeai --api gemini --model gemini-pro\n</code></pre>"},{"location":"llm-integrations/#available-models_2","title":"Available Models:","text":"<ul> <li><code>gemini-pro</code></li> </ul>"},{"location":"llm-integrations/#best-practices_2","title":"Best Practices:","text":"<ul> <li>Gemini models excel at understanding context and generating coherent text.</li> <li>Ensure you have the necessary API credentials set up.</li> </ul>"},{"location":"llm-integrations/#4-offline-mode","title":"4. Offline Mode","text":"<p>Offline mode generates a basic README structure without using any LLM service.</p>"},{"location":"llm-integrations/#configuration_3","title":"Configuration:","text":"<pre><code>readmeai --api offline\n</code></pre>"},{"location":"llm-integrations/#best-practices_3","title":"Best Practices:","text":"<ul> <li>Use offline mode for quick boilerplate generation or when you don't have internet access.</li> <li>Customize the generated README manually after generation.</li> </ul>"},{"location":"llm-integrations/#comparing-llm-services","title":"Comparing LLM Services","text":"Service Pros Cons OpenAI High-quality output, Versatile Requires API key, Costs associated Ollama Free, Privacy-focused, Offline May be slower, Requires local setup Gemini Strong performance, Google integration Requires API key Offline No internet required, Fast Basic output, Limited customization"},{"location":"llm-integrations/#tips-for-optimal-results","title":"Tips for Optimal Results","text":"<ol> <li>Experiment with different models: Try various LLM services and models to find the best fit for your project.</li> <li>Provide clear context: Ensure your repository has well-organized code and documentation to help the LLM generate more accurate content.</li> <li>Fine-tune with CLI options: Use readme-ai's CLI options to customize the output further after choosing your LLM service.</li> <li>Review and edit: Always review the generated README and make necessary edits to ensure accuracy and relevance to your project.</li> </ol> <p>By leveraging these LLM integrations effectively, you can generate comprehensive and accurate README files for your projects with minimal effort.</p>"},{"location":"overview/","title":"Features Overview","text":"<p>Readme-ai offers a comprehensive set of features designed to streamline the creation of high-quality README files for your projects. Here's an overview of the key features:</p> <ol> <li> <p>Flexible README Generation: Combines robust repository context extraction with generative AI to create detailed and accurate README files.</p> </li> <li> <p>Multiple LLM Support: Compatible with various language model APIs, including:</p> </li> <li>OpenAI</li> <li>Ollama</li> <li>Google Gemini</li> <li> <p>Offline Mode (for generating boilerplate READMEs without API calls)</p> </li> <li> <p>Customizable Output: Offers numerous CLI options for tailoring the README to your project's needs:</p> </li> <li>Badge styles and colors</li> <li>Header designs</li> <li>Table of contents styles</li> <li> <p>Project logos</p> </li> <li> <p>Language Agnostic: Works with a wide range of programming languages and project types, automatically detecting and summarizing key aspects of your codebase.</p> </li> <li> <p>Project Analysis: Automatically extracts and presents important information about your project:</p> </li> <li>Directory structure</li> <li>File summaries</li> <li>Dependencies</li> <li> <p>Setup instructions</p> </li> <li> <p>Offline Mode: Generate a basic README structure without requiring an internet connection or API calls.</p> </li> <li> <p>Continuous Integration: Can be integrated into CI/CD pipelines for automated README generation and updates.</p> </li> </ol> <p>For more detailed information on each feature, please refer to the specific feature pages in the navigation menu.</p>"},{"location":"prerequisites/","title":"System Requirements","text":""},{"location":"prerequisites/#dependencies","title":"Dependencies","text":"<ul> <li>Python: <code>3.9</code> or higher</li> <li>Package manager or container runtime: <code>pip</code> or <code>docker</code> recommended.</li> <li>OpenAI API account and API key (other providers coming soon)</li> </ul>"},{"location":"prerequisites/#repository","title":"Repository","text":"<p>A repository URL or local path to your codebase is required run readme-ai. The following are supported:</p> <ul> <li>GitHub</li> <li>GitLab</li> <li>Bitbucket</li> <li>File System</li> </ul>"},{"location":"prerequisites/#llm-api-key","title":"LLM API Key","text":"<p>An OpenAI API account and API key are needed to use readme-ai. The following steps outline the process.</p> \ud83d\udd10 OpenAI API Account Setup <ol> <li>Go to the OpenAI website.</li> <li>Click the \"Sign up for free\" button.</li> <li>Fill out the registration form with your information and agree to the terms of service.</li> <li>Once logged in, click on the \"API\" tab.</li> <li>Follow the instructions to create a new API key.</li> <li>Copy the API key and keep it in a secure place.</li> </ol>"},{"location":"usage/","title":"Usage","text":"<p>This guide covers the basic usage of readme-ai and provides examples for different LLM services.</p>"},{"location":"usage/#basic-usage","title":"Basic Usage","text":"<p>The general syntax for using readme-ai is:</p> <pre><code>readmeai --repository &lt;REPO_URL_OR_PATH&gt; --api &lt;LLM_SERVICE&gt; [OPTIONS]\n</code></pre> <p>Replace <code>&lt;REPO_URL_OR_PATH&gt;</code> with your repository URL or local path, and <code>&lt;LLM_SERVICE&gt;</code> with your chosen LLM service (openai, ollama, gemini, or offline).</p>"},{"location":"usage/#examples","title":"Examples","text":""},{"location":"usage/#using-openai","title":"Using OpenAI","text":"<pre><code>readmeai --repository https://github.com/eli64s/readme-ai \\\n         --api openai \\\n         --model gpt-3.5-turbo\n</code></pre>"},{"location":"usage/#using-ollama","title":"Using Ollama","text":"<pre><code>readmeai --repository https://github.com/eli64s/readme-ai \\\n         --api ollama \\\n         --model llama3\n</code></pre>"},{"location":"usage/#using-google-gemini","title":"Using Google Gemini","text":"<pre><code>readmeai --repository https://github.com/eli64s/readme-ai \\\n         --api gemini \\\n         --model gemini-1.5-flash\n</code></pre>"},{"location":"usage/#offline-mode","title":"Offline Mode","text":"<pre><code>readmeai --repository https://github.com/eli64s/readme-ai \\\n         --api offline\n</code></pre>"},{"location":"usage/#advanced-usage","title":"Advanced Usage","text":"<p>You can customize the output using various options:</p> <pre><code>readmeai --repository https://github.com/eli64s/readme-ai \\\n         --api openai \\\n         --model gpt-4-turbo \\\n         --badge-color blueviolet \\\n         --badge-style flat-square \\\n         --header-style compact \\\n         --toc-style fold \\\n         --temperature 0.1 \\\n         --tree-depth 2 \\\n         --image LLM \\\n         --emojis\n</code></pre> <p>For a full list of options, run:</p> <pre><code>readmeai --help\n</code></pre> <p>See the Configuration page for detailed information on all available options.</p>"}]}